{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">Laboratorio 5</h1>\n",
    "<h4 style=\"text-align:center;\">Cristopher Barrios</h4>\n",
    "<h4 style=\"text-align:center;\">Mariana David</h4>\n",
    "<h5 style=\"text-align:center;\">1/9/2023</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Descargue el archivo train.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cargue los archivos de datos a R o a Python, dependiendo de con qué trabaje. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Limpie y preprocese los datos. Describa de forma detallada las actividades de preprocesamiento \n",
    "que llevó a cabo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.  Se pueden hacer tareas como: \n",
    "- Convertir el texto a mayúsculas o a minúsculas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1       NaN\n",
       "2       NaN\n",
       "3       NaN\n",
       "4       NaN\n",
       "       ... \n",
       "7608    NaN\n",
       "7609    NaN\n",
       "7610    NaN\n",
       "7611    NaN\n",
       "7612    NaN\n",
       "Name: keyword, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.lower()\n",
    "df['location'].str.lower()\n",
    "df['keyword'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quitar los caracteres especiales que aparecen como “#”,”@” o los apóstrofes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjrba\\AppData\\Local\\Temp\\ipykernel_12724\\2394621819.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.text = df.text.str.replace('[#,@,&,(,),!,?,/,{,},%,!]', '')\n",
      "C:\\Users\\cjrba\\AppData\\Local\\Temp\\ipykernel_12724\\2394621819.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.location = df.location.str.replace('[#,@,&,(,),!,?,/,{,},%,!]', '')\n",
      "C:\\Users\\cjrba\\AppData\\Local\\Temp\\ipykernel_12724\\2394621819.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.keyword = df.keyword.str.replace('[#,@,&,(,),!,?,/,{,},%,!]', '')\n"
     ]
    }
   ],
   "source": [
    "df.text = df.text.str.replace('[#,@,&,(,),!,?,/,{,},%,!]', '')\n",
    "df.location = df.location.str.replace('[#,@,&,(,),!,?,/,{,},%,!]', '')\n",
    "df.keyword = df.keyword.str.replace('[#,@,&,(,),!,?,/,{,},%,!]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quitar las url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = [re.sub('\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*','',i) for i in df.text]\n",
    "df.text = [re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', i) for i in df.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Revisar si hay emoticones y quitarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = [re.sub('[^a-zA-Z0-9 ]+','', i) for i in df.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quitar los signos de puntuación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id keyword location  \\\n",
      "0         1     NaN      NaN   \n",
      "1         4     NaN      NaN   \n",
      "2         5     NaN      NaN   \n",
      "3         6     NaN      NaN   \n",
      "4         7     NaN      NaN   \n",
      "...     ...     ...      ...   \n",
      "7608  10869     NaN      NaN   \n",
      "7609  10870     NaN      NaN   \n",
      "7610  10871     NaN      NaN   \n",
      "7611  10872     NaN      NaN   \n",
      "7612  10873     NaN      NaN   \n",
      "\n",
      "                                                   text  target  \n",
      "0     Our Deeds are the Reason of this earthquake Ma...       1  \n",
      "1                 Forest fire near La Ronge Sask Canada       1  \n",
      "2     All residents asked to shelter in place are be...       1  \n",
      "3     13000 people receive wildfires evacuation orde...       1  \n",
      "4     Just got sent this photo from Ruby Alaska as s...       1  \n",
      "...                                                 ...     ...  \n",
      "7608  Two giant cranes holding a bridge collapse int...       1  \n",
      "7609  ariaahrary TheTawniest The out of control wild...       1  \n",
      "7610  M194 0104 UTC5km S of Volcano Hawaii httptcozD...       1  \n",
      "7611  Police investigating after an ebike collided w...       1  \n",
      "7612  The Latest More Homes Razed by Northern Califo...       1  \n",
      "\n",
      "[7613 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Función para quitar signos de puntuación\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "# Aplicar la función a la columna 'text'\n",
    "df['text'] = df['text'].apply(remove_punctuation)\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quitar los artículos, preposiciones y conjunciones (stopwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cjrba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')  # You might need to download NLTK data for stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Our Deeds Reason earthquake May ALLAH Forgive us\n",
      "1                   Forest fire near La Ronge Sask Canada\n",
      "2       All residents asked shelter place notified off...\n",
      "3       13000 people receive wildfires evacuation orde...\n",
      "4       Just got sent photo Ruby Alaska smoke wildfire...\n",
      "                              ...                        \n",
      "7608    Two giant cranes holding bridge collapse nearb...\n",
      "7609    ariaahrary TheTawniest control wild fires Cali...\n",
      "7610    M194 0104 UTC5km S Volcano Hawaii httptcozDtoy...\n",
      "7611    Police investigating ebike collided car Little...\n",
      "7612    Latest More Homes Razed Northern California Wi...\n",
      "Name: text_without_stopwords, Length: 7613, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "stopwords = set(stopwords.words('english') + ['the', 'i', 'a', 'deeds', 'im','rt','jk','btw','lol','yolo','lmao','lmfao','fb','like','get','em', 'I', 'The', 'A', 'Amp', 'amp'])\n",
    "expresiones = ['im','rt','jk','btw','lol','yolo','lmao','lmfao','fb','like','get','em', 'Im', 'in', 'In', '2']\n",
    "for i in expresiones:\n",
    "    stopwords.add(i)\n",
    "\n",
    "df['text_without_stopwords'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "\n",
    "clean_tweets = df['text_without_stopwords']\n",
    "print(df['text_without_stopwords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quitar números si considera que interferirán en la clasificación (quizá debería valorar \n",
    "si quitar o no el 911). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>texto_preprocesado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>our deeds reason earthquake may allah forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "      <td>all residents asked shelter place notified off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>people receive wildfires evacuation orders ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>just got sent photo ruby alaska smoke wildfire...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1              Forest fire near La Ronge Sask Canada   \n",
       "2  All residents asked to shelter in place are be...   \n",
       "3  13000 people receive wildfires evacuation orde...   \n",
       "4  Just got sent this photo from Ruby Alaska as s...   \n",
       "\n",
       "                                  texto_preprocesado  \n",
       "0   our deeds reason earthquake may allah forgive us  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  all residents asked shelter place notified off...  \n",
       "3   people receive wildfires evacuation orders ca...  \n",
       "4  just got sent photo ruby alaska smoke wildfire...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Crear una función para preprocesar el texto\n",
    "def preprocesar_texto(texto):\n",
    "    return re.sub(r'\\d+', '', texto.lower())\n",
    "\n",
    "# Suponiendo que ya tienes un DataFrame llamado 'df' con una columna 'text'\n",
    "df['texto_preprocesado'] = clean_tweets.apply(preprocesar_texto)\n",
    "\n",
    "# Mostrar las primeras filas para ver los cambios\n",
    "df[['text', 'texto_preprocesado']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para observar como va la data\n",
    "clean_tweets.to_csv('output/newTrain.csv', index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "4. Obtenga la frecuencia de las palabras tanto de los tweets de desastres como de los que no. ¿Qué \n",
    "palabras cree que le servirán para hacer un mejor modelo de clasificación?¿vale la pena explorar \n",
    "bigramas o trigramas para analizar contexto? \n",
    "5. Haga un análisis exploratorio de los datos para entenderlos mejor, documente todos los análisis \n",
    "5.1.  Puede, para cada archivo: \n",
    "- Investigar qué palabra se repite más en cada una de las categorías \n",
    "- Hacer una nube de palabras para visualizar las que aparecen con más frecuencia \n",
    "- Hacer un histograma con las palabras que más se repiten\n",
    "- Discutir sobre las palabras que tienen presencia en todas las categorías. \n",
    "- Determinar las palabras positivas, negativas o neutras \n",
    "6. Teniendo en cuenta la cantidad de palabras positivas y negativas del tweet determine qué tan \n",
    "positivo, negativo o neutral es el mismo. \n",
    "7. Luego de analizar los datos determine: \n",
    "7.1.  ¿Cuáles son los 10 tweets más negativos?¿En qué categoría están? \n",
    "7.2.  ¿Cuáles son los 10 tweets más positivos? ¿En qué categoría están? \n",
    "7.3.  ¿Son los tweets de la categoría que indica que habla de un desastre real más negativos que \n",
    "los de la otra categoría? \n",
    "8. Cree una variable que contenga la “negatividad” de cada tweet.  Inclúyala  en  el  conjunto  de \n",
    "datos y entrene nuevamente el modelo de clasificación de la hoja pasada. ¿La inclusión de esta \n",
    "variable mejoró los resultados del modelo de clasificación?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
